{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7heFW2zK4/DmJaCUW3/wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prayan2702/Momentum-Screen/blob/main/Copy_of_RajMomnFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DsAR_COR6ASc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Created on Sat Dec 31 2022\n",
        "\n",
        "@author: Chintan Shah\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def getMedianVolume(data):\n",
        "\treturn(round(data.median(),0))\n",
        "\n",
        "def getDailyReturns(data):\n",
        "\treturn(data.pct_change())\n",
        "\n",
        "def getAbsReturns(data):\n",
        "\tx = (data.iloc[-1]/data.iloc[0] - 1)*100\n",
        "\treturn(round(x, 2))\n",
        "\n",
        "def getVolatility(data):\n",
        "\treturn(round(np.std(data) * np.sqrt(252) * 100, 2))\n",
        "\n",
        "def getMonthlyPrices(data):\n",
        "\tgrps = data.groupby([data.index.year, data.index.month])\n",
        "\tmonthlyPrices = pd.DataFrame()\n",
        "\tfor k in grps:\n",
        "\t\tmonthlyPrices = pd.concat([monthlyPrices, k[1].tail(1)])\n",
        "\t\t# monthlyPrices = monthlyPrices.append(k[1].tail(1))\n",
        "\treturn monthlyPrices\n",
        "\n",
        "def getMonthlyReturns(data):\n",
        "\treturn(data.pct_change())\n",
        "\n",
        "def getSharpe(data):\n",
        "\treturn(round(np.sqrt(252) * data.mean()/data.std(), 2))\n",
        "\n",
        "def getSortino(data):\n",
        "\treturn(np.sqrt(252) * data.mean()/data[data<0].std())\n",
        "\n",
        "def getMaxDrawdown(data):\n",
        "\tcummRet = (data+1).cumprod()\n",
        "\tpeak = cummRet.expanding(min_periods = 1).max()\n",
        "\tdrawdown = (cummRet/peak) - 1\n",
        "\treturn drawdown.min()\n",
        "\n",
        "def getCalmar(data):\n",
        "\treturn(data.mean()*252/abs(getMaxDrawdown(data)))\n",
        "\n",
        "def getAbsMomentumVolAdjusted(absReturn, volatility):\n",
        "\treturn(absReturn/volatility)\n",
        "\n",
        "def getNMonthRoC(data, N):\n",
        "\tret = round((data.iloc[-1]/data.iloc[-1-N] - 1) * 100, 2)\n",
        "\treturn(ret)\n",
        "\n",
        "def getNWeekRoC(data, N):\n",
        "\tret = round((data.iloc[-1]/data.iloc[-1-N] - 1) * 100, 2)\n",
        "\treturn(ret)\n",
        "\n",
        "def getFIP(data):\n",
        "\tretPos = np.sum(data.pct_change()[1:] > 0)\n",
        "\tretNeg = np.sum(data.pct_change()[1:] < 0)\n",
        "\treturn(retPos - retNeg)\n",
        "\n",
        "def getSharpeRoC(roc, volatility):\n",
        "\treturn(round(roc/volatility, 2))\n",
        "\n",
        "def getBeta(dfNifty, data12M):\n",
        "\n",
        "\tdailyReturns = getDailyReturns(pd.concat([dfNifty, data12M], axis = 1))[1:]\n",
        "\n",
        "\tvar = dailyReturns.loc[:, 'Nifty'].var()\n",
        "\n",
        "\tcov = dailyReturns.cov()\n",
        "\n",
        "\tcols = cov.columns[1:]\n",
        "\n",
        "\tbeta = []\n",
        "\n",
        "\tfor k in cols:\n",
        "\t\tbeta.append(round(cov.loc[k, 'Nifty']/var, 2))\n",
        "\n",
        "\treturn beta\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.stats import zscore\n",
        "from datetime import datetime\n",
        "import yfinance as yf\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "universe = ['Nifty50', 'Nifty100', 'Nifty200', 'Nifty250', 'Nifty500', 'All', 'AllNSE']\n",
        "\n",
        "# Pick universe, lookback\n",
        "U = universe[6] #Selecting All NSE Stocks\n",
        "\n",
        "# Two-factor ranking\n",
        "# First sort by Average sharpe of 12M, 9M, 6M and 3M and get the rank\n",
        "# Next sort by deducting 1M ROC from 12M ROC to avoid recency bias and get the rank\n",
        "# Add the above 2 ranks and sort by ascending ranks\n",
        "#rm = ['sharpe12MRoC', 'FIP12M']\n",
        "#rm = ['averageSharpe', '12MROCMinus1MROC']\n",
        "rm = ['averageSharpe']\n",
        "\n",
        "# Apply various filters\n",
        "applyFilter = True\n",
        "\n",
        "print('Universe: ', U)\n",
        "print('Lookback: 12 Months')\n",
        "print('Ranking:', rm)\n",
        "print('Filter:', str(applyFilter))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Dates: shift by 1 month at every rebalance\n",
        "dates = dict()\n",
        "# change the start date below to a year from today's date\n",
        "dates['startDate'] = datetime.strptime('2023-03-26', '%Y-%m-%d')\n",
        "# change the end date below to today\n",
        "dates['endDate'] = datetime.strptime('2024-03-28', '%Y-%m-%d')\n",
        "# calculating dates 1M back, 3M back, 6M back and 9M back\n",
        "dates['date1M'] = dates['endDate'] - relativedelta(months=+1)\n",
        "dates['date3M'] = dates['endDate'] - relativedelta(months=+3)\n",
        "dates['date6M'] = dates['endDate'] - relativedelta(months=+6)\n",
        "dates['date9M'] = dates['endDate'] - relativedelta(months=+9)\n",
        "\n",
        "#Print the dates\n",
        "print('Start Date: ', dates['startDate'])\n",
        "print('9M Date: ', dates['date9M'])\n",
        "print('6M Date: ', dates['date6M'])\n",
        "print('3M Date: ', dates['date3M'])\n",
        "print('1M Date:', dates['date1M'])\n",
        "print('End Date: ', dates['endDate'])\n",
        "print('\\n')\n",
        "\n",
        "# Read index file\n",
        "if U == 'Nifty50':\n",
        "    df = pd.read_csv('/content/ind_nifty50list.csv')\n",
        "elif U == 'Nifty100':\n",
        "    df = pd.read_csv('/content/ind_nifty100list.csv')\n",
        "elif U == 'Nifty200':\n",
        "    df = pd.read_csv('/content/ind_nifty200list.csv')\n",
        "elif U == 'Nifty250':\n",
        "    df = pd.read_csv('/content/ind_niftysmallcap250list.csv')\n",
        "elif U == 'Nifty500':\n",
        "    df = pd.read_csv('/content/ind_nifty500list.csv')\n",
        "elif U == 'All':\n",
        "    df = pd.read_csv('/content/ind_niftytotalmarket_list.csv')\n",
        "elif U == 'AllNSE':\n",
        "    df = pd.read_csv('/content/NSE_EQ_ALL.csv')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(['Series', 'ISIN Code', 'Industry'], axis = 1, inplace = True)\n",
        "\n",
        "# Create Yahoo symbol\n",
        "df['Yahoo_Symbol'] = df.Symbol + '.NS'\n",
        "df = df.set_index('Yahoo_Symbol')\n",
        "symbol = list(df.index)\n",
        "\n",
        "# Get yahoofinance data in chunks of 50\n",
        "CHUNK = 50\n",
        "close = []\n",
        "volume = []\n",
        "for k in range(0, len(symbol), CHUNK):\n",
        "    print(k, end = ',', flush = True)\n",
        "    print(\"\\n\")\n",
        "    _symlist = symbol[k:k+CHUNK]\n",
        "    _x = yf.download(_symlist, start = dates['startDate'], progress = False)\n",
        "    close = _x['Close'] if len(close) == 0 else pd.concat([close, _x['Close']], axis = 1)\n",
        "    volume = _x['Close']*_x['Volume'] if len(volume) == 0 else pd.concat([volume, (_x['Close']*_x['Volume'])], axis = 1)\n",
        "    time.sleep(.5)\n",
        "\n",
        "print(\"Done with downloading DATA \\n\")\n",
        "# Keep the data within the date range for 1 year data\n",
        "data12M = close[:dates['endDate']].copy()\n",
        "volume12M = volume[:dates['endDate']].copy()\n",
        "\n",
        "\n",
        "# At least 12 months of trading is required\n",
        "#data12M.dropna(axis = 1, inplace = True)\n",
        "#volume12M.dropna(axis = 1, inplace = True)\n",
        "data9M = data12M[dates['date9M']:].copy() # Gets last 9M data\n",
        "data6M = data12M[dates['date6M']:].copy() # Gets last 6M data\n",
        "data3M = data12M[dates['date3M']:].copy() # Gets last 3M data\n",
        "data1M = data12M[dates['date1M']:].copy() # Gets last 1M data\n",
        "\n",
        "print(\"Got data slices for each timeframe \\n\")\n",
        "\n",
        "# Stats DataFrame\n",
        "dfStats = pd.DataFrame()\n",
        "\n",
        "# Rate of change\n",
        "dfStats['roc1M'] = getAbsReturns(data1M)\n",
        "dfStats['roc3M'] = getAbsReturns(data3M)\n",
        "dfStats['roc6M'] = getAbsReturns(data6M)\n",
        "dfStats['roc9M'] = getAbsReturns(data9M)\n",
        "dfStats['roc12M'] = getAbsReturns(data12M)\n",
        "\n",
        "print(\"Done calculating ROCs \\n\")\n",
        "\n",
        "\n",
        "# Volatility\n",
        "dfStats['volatility3M'] = getVolatility(getDailyReturns(data3M))\n",
        "dfStats['volatility6M'] = getVolatility(getDailyReturns(data6M))\n",
        "dfStats['volatility9M'] = getVolatility(getDailyReturns(data9M))\n",
        "dfStats['volatility12M'] = getVolatility(getDailyReturns(data12M))\n",
        "\n",
        "print(\"Done calculating Volatility \\n\")\n",
        "\n",
        "dfStats['sharpe12MRoC'] = getSharpeRoC(dfStats['roc12M'], dfStats['volatility12M'])\n",
        "dfStats['sharpe9MRoC'] = getSharpeRoC(dfStats['roc9M'], dfStats['volatility9M'])\n",
        "dfStats['sharpe6MRoC'] = getSharpeRoC(dfStats['roc6M'], dfStats['volatility6M'])\n",
        "dfStats['sharpe3MRoC'] = getSharpeRoC(dfStats['roc3M'], dfStats['volatility3M'])\n",
        "\n",
        "#MAIN FACTORS for ranking stocks. we are using 2 factors\n",
        "dfStats['averageSharpe'] = dfStats[[\"sharpe12MRoC\",\"sharpe9MRoC\", \"sharpe6MRoC\",\"sharpe3MRoC\"]].mean(axis=1) #1st Factor\n",
        "#dfStats['12MROCMinus1MROC'] = dfStats[\"roc12M\"] - dfStats[\"roc1M\"] #2nd Factor\n",
        "\n",
        "print(\"Done calculating Sharpe  \\n\")\n",
        "\n",
        "dfStats['volume'] = getMedianVolume(volume12M)\n",
        "\n",
        "# close and ema\n",
        "dfStats['Close'] = round(data12M.iloc[-1], 2)\n",
        "#fileName = './OutputMonthly/RAW_' + dates['endDate'].strftime('%Y-%m-%d') + '_' + U + '_' + '12M' + '_lookback' + '.csv'\n",
        "#data12M.to_csv(fileName, index = False, float_format = \"%.2f\")\n",
        "data12M.fillna(0, inplace=True)\n",
        "dfStats['dma100d'] = round(data12M.rolling(window=100).mean().iloc[-1], 2)\n",
        "dfStats['dma200d'] = round(data12M.rolling(window=200).mean().iloc[-1], 2)\n",
        "\n",
        "#PRINT OUT ALL THE STOCKS DATA without any filters\n",
        "print(\"\\n Writing unfiltered data to file. Shape in next line \\n\")\n",
        "print(dfStats.shape)\n",
        "fileName = '/content/Unfiltered' + dates['endDate'].strftime('%Y-%m-%d') + '_' + U + '_' + '12M' + '_lookback' + '.csv'\n",
        "unfiltered = dfStats.reset_index().rename(columns = {'index':'symbol'})\n",
        "unfiltered.to_csv(fileName, index = False, float_format = \"%.2f\")\n",
        "\n",
        "# Get Nifty data (Additional added condition)\n",
        "dfNifty = yf.download(\"^NSEI\", start = dates['startDate'], progress = False)['Close']\n",
        "dfNifty = dfNifty.to_frame().rename(columns = {'Close':'Nifty'})\n",
        "\n",
        "# Get stock beta (Additional added condition)\n",
        "dfStats['Beta'] = getBeta(dfNifty, data12M)\n",
        "\n",
        "#Ignore(drop) Top 10 percent Highest Beta stock against Nifty from the selected universe (Additional added condition)\n",
        "dfStats = dfStats.sort_values(by = [\"Beta\"], axis = 0, ascending=False)\n",
        "dfStats = dfStats.tail(len(dfStats) - round(len(dfStats)*0.1))\n",
        "\n",
        "\n",
        "# Apply filters: e.g. RoC12M > FD rate\n",
        "cond1 = dfStats['volume'] > 10000000 #volume filter\n",
        "cond2 = dfStats['Close'] > dfStats['dma100d'] # above 100-day DMA\n",
        "cond3 = dfStats['Close'] > dfStats['dma200d'] # above 200-day DMA\n",
        "cond4 = dfStats['roc12M'] > 7 #12M ROC above G-sec rate\n",
        "cond = cond1 & cond2 & cond3 & cond4\n",
        "\n",
        "if applyFilter == True:\n",
        "    filtered = dfStats[cond]\n",
        "elif applyFilter == False:\n",
        "    filtered = dfStats\n",
        "\n",
        "\n",
        "print(\"Applied Filters \\n\")\n",
        "\n",
        "#FIRST, sort by average Sharpe for 12M, 9M, 6M and 3M\n",
        "output = filtered.sort_values(rm[0], ascending = False).reset_index().rename(columns = {'index':'symbol'})\n",
        "# Assign rank\n",
        "output['Rank1'] = range(1, output.shape[0] + 1)\n",
        "\n",
        "#SECOND, sort by (12M ROC - 1M ROC)\n",
        "#output = output.sort_values(rm[1], ascending = False)\n",
        "# Assign rank\n",
        "#output['Rank2'] = range(1, output.shape[0] + 1)\n",
        "\n",
        "#Now, combine both the ranks and sort with ranks sorted in ascending order\n",
        "#output['FinalRank'] = output['Rank1'] + output['Rank2']\n",
        "output['FinalRank'] = output['Rank1']\n",
        "output = output.sort_values('FinalRank', ascending = True)\n",
        "\n",
        "print(\"\\n Writing data to file \\n\")\n",
        "\n",
        "fileName = '/content/Filtered' + dates['endDate'].strftime('%Y-%m-%d') + '_' + U + '_' + '12M' + '_lookback' + '.csv'\n",
        "output.to_csv(fileName, index = False, float_format = \"%.2f\")\n",
        "\n",
        "print(\"\\n Successfully Done \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZeOZJx26B54",
        "outputId": "fb593eea-236e-4a66-89eb-44860a7fb8e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Universe:  AllNSE\n",
            "Lookback: 12 Months\n",
            "Ranking: ['averageSharpe']\n",
            "Filter: True\n",
            "\n",
            "\n",
            "Start Date:  2023-03-26 00:00:00\n",
            "9M Date:  2023-06-28 00:00:00\n",
            "6M Date:  2023-09-28 00:00:00\n",
            "3M Date:  2023-12-28 00:00:00\n",
            "1M Date: 2024-02-28 00:00:00\n",
            "End Date:  2024-03-28 00:00:00\n",
            "\n",
            "\n",
            "0,\n",
            "\n",
            "50,\n",
            "\n",
            "100,\n",
            "\n",
            "150,\n",
            "\n",
            "200,\n",
            "\n",
            "250,\n",
            "\n",
            "300,\n",
            "\n",
            "350,\n",
            "\n",
            "400,\n",
            "\n",
            "450,\n",
            "\n",
            "500,\n",
            "\n",
            "550,\n",
            "\n",
            "600,\n",
            "\n",
            "650,\n",
            "\n",
            "700,\n",
            "\n",
            "750,\n",
            "\n",
            "800,\n",
            "\n",
            "850,\n",
            "\n",
            "900,\n",
            "\n",
            "950,\n",
            "\n",
            "1000,\n",
            "\n",
            "1050,\n",
            "\n",
            "1100,\n",
            "\n",
            "1150,\n",
            "\n",
            "1200,\n",
            "\n",
            "1250,\n",
            "\n",
            "1300,\n",
            "\n",
            "1350,\n",
            "\n",
            "1400,\n",
            "\n",
            "1450,\n",
            "\n",
            "1500,\n",
            "\n",
            "1550,\n",
            "\n",
            "1600,\n",
            "\n",
            "Done with downloading DATA \n",
            "\n",
            "Got data slices for each timeframe \n",
            "\n",
            "Done calculating ROCs \n",
            "\n",
            "Done calculating Volatility \n",
            "\n",
            "Done calculating Sharpe  \n",
            "\n",
            "\n",
            " Writing unfiltered data to file. Shape in next line \n",
            "\n",
            "(1641, 18)\n",
            "Applied Filters \n",
            "\n",
            "\n",
            " Writing data to file \n",
            "\n",
            "\n",
            " Successfully Done \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHYBKVjw-59I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
